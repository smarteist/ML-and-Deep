{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuning BERT and Exploring Its Variants\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Bidirectional Encoder Representations from Transformers (BERT) has significantly advanced Natural Language Processing (NLP) by providing powerful, pre-trained language representations. Fine-tuning BERT for specific downstream tasks enables leveraging its deep understanding of language to achieve state-of-the-art performance.\n",
    "\n",
    "In this notebook, we will:\n",
    "\n",
    "1. **Fine-Tune BERT for Various NLP Tasks:**\n",
    "   - **Question Answering (QA)**\n",
    "   - **Named Entity Recognition (NER)**\n",
    "\n",
    "2. **Explore BERT Variants and Extensions:**\n",
    "   - **RoBERTa**\n",
    "   - **DistilBERT**\n",
    "   - **ALBERT**\n",
    "   - **Domain-Specific BERT Models**\n",
    "\n",
    "By the end of this notebook, you'll have hands-on experience fine-tuning BERT for different applications and an understanding of its powerful variants.\n",
    "\n",
    "**Resources for Further Reading:**\n",
    "\n",
    "- [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805) by Devlin et al.\n",
    "- [The Illustrated BERT, ELMo, and co. (How NLP Cracked Transfer Learning)](http://jalammar.github.io/illustrated-bert/)\n",
    "- [Hugging Face Transformers Documentation](https://huggingface.co/transformers/)\n",
    "- [The Illustrated Transformer](http://jalammar.github.io/illustrated-transformer/)\n",
    "\n",
    "**Prerequisites:**\n",
    "\n",
    "- Basic understanding of Python and PyTorch\n",
    "- Familiarity with neural network concepts\n",
    "- Knowledge of NLP tasks and tokenization\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Fine-Tuning BERT\n",
    "\n",
    "Fine-tuning involves taking a pre-trained BERT model and training it on a specific task with task-specific data. We'll explore fine-tuning BERT for three popular NLP tasks: Text Classification, Question Answering, and Named Entity Recognition.\n",
    "\n",
    "### 1.1 Fine-Tuning BERT for Question Answering (QA)\n",
    "\n",
    "**Objective:** Given a context paragraph and a question, predict the span of text in the context that answers the question using the SQuAD (Stanford Question Answering Dataset).\n",
    "\n",
    "#### 1.1.1 Setup\n",
    "\n",
    "First, ensure that the necessary libraries are installed. We'll primarily use Hugging Face's `transformers` library, which provides easy-to-use interfaces for BERT and its variants.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T10:16:56.039610Z",
     "iopub.status.busy": "2024-12-11T10:16:56.039264Z",
     "iopub.status.idle": "2024-12-11T10:17:04.599240Z",
     "shell.execute_reply": "2024-12-11T10:17:04.598317Z",
     "shell.execute_reply.started": "2024-12-11T10:16:56.039577Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.46.3)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.1.0)\n",
      "Requirement already satisfied: evaluate in /opt/conda/lib/python3.10/site-packages (0.4.3)\n",
      "Requirement already satisfied: seqeval in /opt/conda/lib/python3.10/site-packages (1.2.2)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (3.7.5)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.2.2)\n",
      "Requirement already satisfied: seaborn in /opt/conda/lib/python3.10/site-packages (0.12.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.6.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.6.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch datasets evaluate seqeval matplotlib scikit-learn datasets seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T19:56:54.551470Z",
     "iopub.status.busy": "2024-12-10T19:56:54.551039Z",
     "iopub.status.idle": "2024-12-10T19:56:54.585341Z",
     "shell.execute_reply": "2024-12-10T19:56:54.583876Z",
     "shell.execute_reply.started": "2024-12-10T19:56:54.551431Z"
    }
   },
   "source": [
    "#### 1.1.1 Loading and Preprocessing the SQuAD Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T10:17:04.601534Z",
     "iopub.status.busy": "2024-12-11T10:17:04.601227Z",
     "iopub.status.idle": "2024-12-11T10:17:07.557792Z",
     "shell.execute_reply": "2024-12-11T10:17:07.557021Z",
     "shell.execute_reply.started": "2024-12-11T10:17:04.601506Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "062aecf1f4cb4d01bc7184506580b3e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/7.62k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9d40ea9b8b346cc9544e87a9de610f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/14.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0df68857907549c3ac42c023dae98225",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/1.82M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "994c4757284b4b1587bf6492b7c8c2b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/87599 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5438d3c52ebc44e996a5574ed2b1ee2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/10570 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
      "        num_rows: 87599\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
      "        num_rows: 10570\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForQuestionAnswering, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load the SQuAD dataset\n",
    "squad = load_dataset('squad')\n",
    "\n",
    "# Inspect the dataset\n",
    "print(squad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1.2 Tokenization and Alignment\n",
    "\n",
    "Tokenize the inputs, ensuring that the model can predict the start and end positions of the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T10:18:53.121866Z",
     "iopub.status.busy": "2024-12-11T10:18:53.121431Z",
     "iopub.status.idle": "2024-12-11T10:23:43.431931Z",
     "shell.execute_reply": "2024-12-11T10:23:43.430996Z",
     "shell.execute_reply.started": "2024-12-11T10:18:53.121833Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7a641d27fba4bc4b020b23848db8704",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/87599 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "040effc6ec9a4e9faa8b8687d1c5a037",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10570 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e3e3aaba1ca42f2b1b64c3c7f31062f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/87599 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "361208a8957f44c6be86e8ac642aa0f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10570 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the dataset: ['id', 'answers', 'input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "# Initialize the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "qa_model = BertForQuestionAnswering.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Move the model to the desired device (GPU or CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "qa_model.to(device)\n",
    "\n",
    "def tokenize_qa(examples):\n",
    "    return tokenizer(\n",
    "        examples['question'],\n",
    "        examples['context'],\n",
    "        truncation=\"only_second\",  # Truncate only the context\n",
    "        padding='max_length',\n",
    "        max_length=512,\n",
    "        return_offsets_mapping=True  # Needed for answer alignment\n",
    "    )\n",
    "\n",
    "# Apply tokenization WITHOUT removing 'id' and 'answers'\n",
    "tokenized_squad = squad.map(\n",
    "    tokenize_qa,\n",
    "    batched=True,\n",
    "    remove_columns=['title', 'context', 'question']  # Keep 'id' and 'answers'\n",
    ")\n",
    "\n",
    "def align_answers(examples):\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "    for i in range(len(examples['input_ids'])):\n",
    "        # Get the answer's character start and end positions\n",
    "        answer_start_char = examples['answers'][i]['answer_start'][0]\n",
    "        answer_text = examples['answers'][i]['text'][0]\n",
    "        answer_end_char = answer_start_char + len(answer_text)\n",
    "\n",
    "        # Get the offset mappings for the current example\n",
    "        offsets = examples['offset_mapping'][i]\n",
    "\n",
    "        # Initialize start and end token positions\n",
    "        start_pos = 0\n",
    "        end_pos = 0\n",
    "\n",
    "        # Find the start token\n",
    "        for idx, (start, end) in enumerate(offsets):\n",
    "            if start <= answer_start_char < end:\n",
    "                start_pos = idx\n",
    "                break\n",
    "\n",
    "        # Find the end token\n",
    "        for idx, (start, end) in enumerate(offsets):\n",
    "            if start < answer_end_char <= end:\n",
    "                end_pos = idx\n",
    "                break\n",
    "\n",
    "        # Handle cases where the answer might not be fully contained within the max_length\n",
    "        if not (start_pos and end_pos):\n",
    "            start_pos = 0\n",
    "            end_pos = 0\n",
    "\n",
    "        start_positions.append(start_pos)\n",
    "        end_positions.append(end_pos)\n",
    "\n",
    "    examples['start_positions'] = start_positions\n",
    "    examples['end_positions'] = end_positions\n",
    "    return examples\n",
    "\n",
    "# Apply answer alignment WITHOUT removing 'answers' yet\n",
    "tokenized_squad = tokenized_squad.map(\n",
    "    align_answers,\n",
    "    batched=True,\n",
    "    remove_columns=['offset_mapping']  # Remove offset_mapping after alignment\n",
    ")\n",
    "\n",
    "# Verify columns\n",
    "print(\"Columns in the dataset:\", tokenized_squad['validation'].column_names)\n",
    "# Expected Output: ['id', 'input_ids', 'token_type_ids', 'attention_mask', 'answers', 'start_positions', 'end_positions']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note:* Aligning the character positions of answers to token positions is non-trivial and requires handling the mapping between tokens and original text. Hugging Face provides tools to facilitate this, but for brevity, we'll assume the data is already aligned.\n",
    "\n",
    "#### 1.1.3 Creating DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T10:24:56.192553Z",
     "iopub.status.busy": "2024-12-11T10:24:56.191714Z",
     "iopub.status.idle": "2024-12-11T10:24:56.206334Z",
     "shell.execute_reply": "2024-12-11T10:24:56.205400Z",
     "shell.execute_reply.started": "2024-12-11T10:24:56.192518Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training batches (QA): 250\n",
      "Number of testing batches (QA): 25\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Set format for PyTorch, including 'id' and 'answers' without converting them to tensors\n",
    "tokenized_squad.set_format(\n",
    "    type='torch',\n",
    "    columns=['input_ids', 'attention_mask', 'start_positions', 'end_positions', 'id', 'answers']\n",
    ")\n",
    "\n",
    "# Use a subset for demonstration to reduce training time\n",
    "train_qa = tokenized_squad['train'].select(range(1000))\n",
    "test_qa = tokenized_squad['validation'].select(range(100))\n",
    "\n",
    "train_loader_qa = DataLoader(train_qa, batch_size=4, shuffle=True)\n",
    "test_loader_qa = DataLoader(test_qa, batch_size=4)\n",
    "\n",
    "print(\"Number of training batches (QA):\", len(train_loader_qa))\n",
    "print(\"Number of testing batches (QA):\", len(test_loader_qa))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.4 Defining the QA Model\n",
    "\n",
    "Load the pre-trained BERT model for question answering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T10:26:13.648718Z",
     "iopub.status.busy": "2024-12-11T10:26:13.647906Z",
     "iopub.status.idle": "2024-12-11T10:26:14.082617Z",
     "shell.execute_reply": "2024-12-11T10:26:14.081759Z",
     "shell.execute_reply.started": "2024-12-11T10:26:13.648684Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch keys: dict_keys(['id', 'answers', 'input_ids', 'attention_mask', 'start_positions', 'end_positions'])\n",
      "Batch 'id' example: 56be4db0acb8001400a502ec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForQuestionAnswering(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForQuestionAnswering\n",
    "\n",
    "\n",
    "# Verify that 'id' is present in batches\n",
    "for batch in test_loader_qa:\n",
    "    print(\"Batch keys:\", batch.keys())\n",
    "    print(\"Batch 'id' example:\", batch['id'][0])\n",
    "    break  # Only inspect the first batch\n",
    "\n",
    "# Reload the model (if not already loaded)\n",
    "qa_model = BertForQuestionAnswering.from_pretrained('bert-base-uncased')\n",
    "qa_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.5 Setting Up the Optimizer and Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T10:26:18.750425Z",
     "iopub.status.busy": "2024-12-11T10:26:18.750091Z",
     "iopub.status.idle": "2024-12-11T10:26:18.768121Z",
     "shell.execute_reply": "2024-12-11T10:26:18.767262Z",
     "shell.execute_reply.started": "2024-12-11T10:26:18.750398Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "\n",
    "# Setup optimizer and scheduler\n",
    "epochs = 2\n",
    "total_steps = len(train_loader_qa) * epochs\n",
    "\n",
    "optimizer_qa = AdamW(qa_model.parameters(), lr=3e-5)\n",
    "\n",
    "scheduler_qa = get_linear_schedule_with_warmup(optimizer_qa,\n",
    "                                              num_warmup_steps=0,\n",
    "                                              num_training_steps=total_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.6 Training the QA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T10:26:27.106474Z",
     "iopub.status.busy": "2024-12-11T10:26:27.105797Z",
     "iopub.status.idle": "2024-12-11T10:29:47.405919Z",
     "shell.execute_reply": "2024-12-11T10:29:47.405135Z",
     "shell.execute_reply.started": "2024-12-11T10:26:27.106439Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "875d17b5b7764201a20375b4814b38da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1de0580a71441cebdc161b8ffd228f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/3.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ba31b607b3b4bd5a26b6c055a5e38a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training QA:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 3.9648\n",
      "\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23dbaffb156a42aca1cc5fc07bcb7bca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training QA:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 2.1461\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Initialize the SQuAD metric\n",
    "squad_metric = evaluate.load('squad')\n",
    "\n",
    "# Function to calculate QA accuracy (simplified)\n",
    "def qa_accuracy(preds, labels):\n",
    "    # This is a simplified version; proper evaluation requires exact match and F1\n",
    "    return (preds == labels).sum().item() / len(labels)\n",
    "\n",
    "# Training Loop\n",
    "qa_model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f'\\nEpoch {epoch + 1}/{epochs}')\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(train_loader_qa, desc=\"Training QA\")\n",
    "    \n",
    "    for batch in progress_bar:\n",
    "        optimizer_qa.zero_grad()\n",
    "        \n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        start_positions = batch['start_positions'].to(device)\n",
    "        end_positions = batch['end_positions'].to(device)\n",
    "        \n",
    "        outputs = qa_model(input_ids=input_ids, attention_mask=attention_mask,\n",
    "                           start_positions=start_positions, end_positions=end_positions)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer_qa.step()\n",
    "        scheduler_qa.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        progress_bar.set_postfix({'loss': loss.item()})\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader_qa)\n",
    "    print(f'Training Loss: {avg_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.7 Evaluating the QA Model\n",
    "\n",
    "Assess the model's performance on the test set using metrics like Exact Match (EM) and F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T10:30:18.840373Z",
     "iopub.status.busy": "2024-12-11T10:30:18.839231Z",
     "iopub.status.idle": "2024-12-11T10:30:23.446863Z",
     "shell.execute_reply": "2024-12-11T10:30:23.445846Z",
     "shell.execute_reply.started": "2024-12-11T10:30:18.840335Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5a50f8007194d6fb6765c058733e689",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating QA:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exact Match: 49.00\n",
      "F1 Score: 53.09\n"
     ]
    }
   ],
   "source": [
    "# Evaluation Code Starts Here\n",
    "qa_model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# Initialize lists to store predictions and references\n",
    "predictions = []\n",
    "references = []\n",
    "\n",
    "# Create a mapping from 'id' to the original example for quick lookup\n",
    "original_validation = load_dataset('squad', split='validation').select(range(100))\n",
    "id_to_example = {example['id']: example for example in original_validation}\n",
    "\n",
    "for batch in tqdm(test_loader_qa, desc=\"Evaluating QA\"):\n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    ids = batch['id']  # This is a list of strings\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = qa_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        start_logits = outputs.start_logits\n",
    "        end_logits = outputs.end_logits\n",
    "\n",
    "    # Move logits to CPU and convert to numpy\n",
    "    start_logits = start_logits.cpu().numpy()\n",
    "    end_logits = end_logits.cpu().numpy()\n",
    "\n",
    "    # Iterate over each example in the batch\n",
    "    for i in range(len(ids)):\n",
    "        id_ = ids[i]  # Already a string, no need for .item()\n",
    "\n",
    "        # Retrieve the original example using the 'id'\n",
    "        example = id_to_example[id_]\n",
    "        context = example['context']\n",
    "        question = example['question']\n",
    "        answers = example['answers']['text']\n",
    "\n",
    "        # Get the most likely start and end positions\n",
    "        start_idx = start_logits[i].argmax()\n",
    "        end_idx = end_logits[i].argmax()\n",
    "\n",
    "        # Decode the tokens to get the answer string\n",
    "        tokens = tokenizer.convert_ids_to_tokens(input_ids[i])\n",
    "\n",
    "        # Handle cases where end_idx is before start_idx\n",
    "        if end_idx < start_idx:\n",
    "            answer = \"\"\n",
    "        else:\n",
    "            # Join the tokens from start_idx to end_idx\n",
    "            answer_tokens = tokens[start_idx:end_idx + 1]\n",
    "            # Clean up tokens\n",
    "            answer = tokenizer.convert_tokens_to_string(answer_tokens)\n",
    "\n",
    "        # Append only 'id' and 'prediction_text' to predictions\n",
    "        predictions.append({\n",
    "            'id': id_,\n",
    "            'prediction_text': answer\n",
    "        })\n",
    "\n",
    "        # Append to references as per SQuAD metric requirements\n",
    "        references.append({\n",
    "            'id': id_,\n",
    "            'answers': {\n",
    "                'text': answers,\n",
    "                'answer_start': example['answers']['answer_start']\n",
    "            }\n",
    "        })\n",
    "\n",
    "# Compute the metrics\n",
    "results = squad_metric.compute(predictions=predictions, references=references)\n",
    "\n",
    "print(f\"\\nExact Match: {results['exact_match']:.2f}\")\n",
    "print(f\"F1 Score: {results['f1']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note:* For a comprehensive evaluation, use the full SQuAD dataset and proper answer alignment.\n",
    "\n",
    "---\n",
    "\n",
    "### 1.2 Fine-Tuning BERT for Named Entity Recognition (NER)\n",
    "\n",
    "**Objective:** Identify and classify named entities (e.g., person, organization, location) in text using the CoNLL-2003 dataset.\n",
    "\n",
    "#### 1.2.1 Loading and Preprocessing the CoNLL-2003 Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T10:30:30.524998Z",
     "iopub.status.busy": "2024-12-11T10:30:30.524309Z",
     "iopub.status.idle": "2024-12-11T10:30:46.096191Z",
     "shell.execute_reply": "2024-12-11T10:30:46.095448Z",
     "shell.execute_reply.started": "2024-12-11T10:30:30.524963Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b7576f076da447b872c47b396411e97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/12.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a7a70c4da0e457b8f20b6404c29da58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "conll2003.py:   0%|          | 0.00/9.57k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "The repository for conll2003 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/conll2003.\n",
      "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
      "\n",
      "Do you wish to run the custom code? [y/N]  y\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7056949edd04a79b591295b11e52541",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/983k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab45dfd973404af0be3434e4477bbf16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/14041 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "372fc4ca1b9e4695941370123e210131",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/3250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54da550660454af48465cd343958e415",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/3453 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
      "        num_rows: 14041\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
      "        num_rows: 3250\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
      "        num_rows: 3453\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForTokenClassification\n",
    "\n",
    "# Load the CoNLL-2003 NER dataset\n",
    "ner = load_dataset('conll2003')\n",
    "\n",
    "# Inspect the dataset\n",
    "print(ner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2 Tokenization and Alignment\n",
    "\n",
    "Tokenize the inputs, ensuring that the labels align with the tokenized words.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T10:33:12.636717Z",
     "iopub.status.busy": "2024-12-11T10:33:12.635858Z",
     "iopub.status.idle": "2024-12-11T10:33:16.205728Z",
     "shell.execute_reply": "2024-12-11T10:33:16.204841Z",
     "shell.execute_reply.started": "2024-12-11T10:33:12.636682Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER Labels: ['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f77370ec19bc44ecae30f0ec15d2fb39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14041 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47b378bed46a41aeb5ca9b24f49ee93e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2f60653c41b41dca1a997e9373cb931",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3453 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training batches (NER): 1756\n",
      "Number of testing batches (NER): 432\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizerFast\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Get the label list from the dataset\n",
    "label_list = ner['train'].features['ner_tags'].feature.names\n",
    "num_labels = len(label_list)\n",
    "print(\"NER Labels:\", label_list)\n",
    "\n",
    "# Initialize the fast tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples['tokens'],\n",
    "        truncation=True,\n",
    "        is_split_into_words=True,\n",
    "        padding='max_length',\n",
    "        max_length=128\n",
    "    )\n",
    "    \n",
    "    labels = []\n",
    "    for i, label in enumerate(examples['ner_tags']):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)  # Special tokens\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(-100)  # Subsequent tokens in a word\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "    \n",
    "    tokenized_inputs['labels'] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "# Apply tokenization and label alignment\n",
    "tokenized_ner = ner.map(tokenize_and_align_labels, batched=True)\n",
    "\n",
    "# Set format to PyTorch tensors\n",
    "tokenized_ner.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "# Create DataLoaders\n",
    "train_ner = tokenized_ner['train']\n",
    "validation_ner = tokenized_ner['validation']\n",
    "test_ner = tokenized_ner['test']\n",
    "\n",
    "train_loader_ner = DataLoader(train_ner, batch_size=8, shuffle=True)\n",
    "validation_loader_ner = DataLoader(validation_ner, batch_size=8)\n",
    "test_loader_ner = DataLoader(test_ner, batch_size=8)\n",
    "\n",
    "print(\"Number of training batches (NER):\", len(train_loader_ner))\n",
    "print(\"Number of testing batches (NER):\", len(test_loader_ner))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.3 Defining the NER Model\n",
    "\n",
    "Load the pre-trained BERT model for token classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T10:34:50.179913Z",
     "iopub.status.busy": "2024-12-11T10:34:50.179200Z",
     "iopub.status.idle": "2024-12-11T10:34:50.532898Z",
     "shell.execute_reply": "2024-12-11T10:34:50.532035Z",
     "shell.execute_reply.started": "2024-12-11T10:34:50.179877Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForTokenClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForTokenClassification\n",
    "\n",
    "ner_model = BertForTokenClassification.from_pretrained('bert-base-uncased', num_labels=num_labels)\n",
    "\n",
    "# Move the model to the desired device (GPU or CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "ner_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.4 Setting Up the Optimizer and Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T10:35:11.738858Z",
     "iopub.status.busy": "2024-12-11T10:35:11.738022Z",
     "iopub.status.idle": "2024-12-11T10:35:11.745919Z",
     "shell.execute_reply": "2024-12-11T10:35:11.745210Z",
     "shell.execute_reply.started": "2024-12-11T10:35:11.738823Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "epochs = 3\n",
    "total_steps = len(train_loader_ner) * epochs\n",
    "\n",
    "optimizer_ner = AdamW(ner_model.parameters(), lr=2e-5)\n",
    "\n",
    "scheduler_ner = get_linear_schedule_with_warmup(optimizer_ner,\n",
    "                                                num_warmup_steps=0,\n",
    "                                                num_training_steps=total_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.5 Training the NER Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T10:35:32.532353Z",
     "iopub.status.busy": "2024-12-11T10:35:32.532032Z",
     "iopub.status.idle": "2024-12-11T10:51:39.702747Z",
     "shell.execute_reply": "2024-12-11T10:51:39.701814Z",
     "shell.execute_reply.started": "2024-12-11T10:35:32.532328Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f9b7592339e4a5f86c21798e11a7f9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training NER:   0%|          | 0/1756 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1157, Training NER Accuracy: 0.9679\n",
      "\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e21fea3952b4cd089c5367c31261b6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training NER:   0%|          | 0/1756 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0322, Training NER Accuracy: 0.9912\n",
      "\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaf79af51bcf481db99390c42bdf8737",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training NER:   0%|          | 0/1756 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0176, Training NER Accuracy: 0.9955\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Function to calculate NER accuracy (token-level)\n",
    "def ner_accuracy(preds, labels):\n",
    "    preds = torch.argmax(preds, dim=2)\n",
    "    valid = labels != -100\n",
    "    correct = (preds == labels) & valid\n",
    "    return correct.sum().item() / valid.sum().item()\n",
    "\n",
    "# Set the model to training mode\n",
    "ner_model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f'\\nEpoch {epoch + 1}/{epochs}')\n",
    "    total_loss = 0\n",
    "    total_acc = 0\n",
    "    num_batches = 0\n",
    "    progress_bar = tqdm(train_loader_ner, desc=\"Training NER\")\n",
    "    \n",
    "    for batch in progress_bar:\n",
    "        optimizer_ner.zero_grad()\n",
    "        \n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        outputs = ner_model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer_ner.step()\n",
    "        scheduler_ner.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        total_acc += ner_accuracy(logits, labels)\n",
    "        num_batches += 1\n",
    "        \n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix({\n",
    "            'loss': loss.item(),\n",
    "            'accuracy': total_acc / num_batches  # Avoid division by zero\n",
    "        })\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader_ner)\n",
    "    avg_acc = total_acc / len(train_loader_ner)\n",
    "    print(f'Training Loss: {avg_loss:.4f}, Training NER Accuracy: {avg_acc:.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.6 Evaluating the NER Model\n",
    "\n",
    "Assess the model's performance on the test set using metrics like Precision, Recall, and F1 score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T10:51:39.704482Z",
     "iopub.status.busy": "2024-12-11T10:51:39.704204Z",
     "iopub.status.idle": "2024-12-11T10:52:03.563930Z",
     "shell.execute_reply": "2024-12-11T10:52:03.563012Z",
     "shell.execute_reply.started": "2024-12-11T10:51:39.704455Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9169b40d61f149c4990f954f95632e8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/6.34k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cedd32a6d523476d887ce7bfd947edbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating NER:   0%|          | 0/432 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "def safe_label_mapping(label_indices, label_list):\n",
    "    mapped_labels = []\n",
    "    for idx in label_indices:\n",
    "        try:\n",
    "            mapped_labels.append(label_list[idx])\n",
    "        except IndexError:\n",
    "            # Handle unexpected label indices\n",
    "            mapped_labels.append(\"O\")\n",
    "    return mapped_labels\n",
    "\n",
    "metric = evaluate.load(\"seqeval\")\n",
    "\n",
    "# Set ner_model to evaluation mode\n",
    "ner_model.eval()\n",
    "\n",
    "# Initialize lists to store predictions and references\n",
    "all_predictions = []\n",
    "all_references = []\n",
    "\n",
    "# Disable gradient computation for evaluation\n",
    "with torch.no_grad():\n",
    "    for batch_idx, batch in enumerate(tqdm(test_loader_ner, desc=\"Evaluating NER\")):\n",
    "        try:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "        except KeyError as e:\n",
    "            print(f\"Missing key in batch {batch_idx}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # Forward pass\n",
    "            outputs = ner_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            \n",
    "            # Get the predicted class by taking the argmax\n",
    "            predictions = torch.argmax(logits, dim=-1)\n",
    "        except Exception as e:\n",
    "            print(f\"Error during model inference on batch {batch_idx}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        # Move tensors to CPU and convert to numpy arrays\n",
    "        predictions = predictions.cpu().numpy()\n",
    "        true_labels = labels.cpu().numpy()\n",
    "        masks = attention_mask.cpu().numpy()\n",
    "        \n",
    "        for i in range(len(input_ids)):\n",
    "            # Apply the attention mask to filter out padding tokens\n",
    "            active_indices = masks[i] == 1\n",
    "            pred_labels = predictions[i][active_indices]\n",
    "            true_label_ids = true_labels[i][active_indices]\n",
    "            \n",
    "            # Filter out labels with value -100 (ignored index)\n",
    "            valid_indices = true_label_ids != -100\n",
    "            pred_labels = pred_labels[valid_indices]\n",
    "            true_label_ids = true_label_ids[valid_indices]\n",
    "            \n",
    "            # Safely map label IDs to label names\n",
    "            pred_label_names = safe_label_mapping(pred_labels, label_list)\n",
    "            true_label_names = safe_label_mapping(true_label_ids, label_list)\n",
    "            \n",
    "            all_predictions.append(pred_label_names)\n",
    "            all_references.append(true_label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T10:53:24.573847Z",
     "iopub.status.busy": "2024-12-11T10:53:24.573440Z",
     "iopub.status.idle": "2024-12-11T10:53:25.525919Z",
     "shell.execute_reply": "2024-12-11T10:53:25.524836Z",
     "shell.execute_reply.started": "2024-12-11T10:53:24.573814Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NER Evaluation Results:\n",
      "Precision: 0.8945\n",
      "Recall: 0.9111\n",
      "F1 Score: 0.9027\n",
      "Accuracy: 0.9804\n"
     ]
    }
   ],
   "source": [
    "results = metric.compute(predictions=all_predictions, references=all_references)\n",
    "\n",
    "\n",
    "# Display evaluation results\n",
    "print(\"\\nNER Evaluation Results:\")\n",
    "print(f\"Precision: {results.get('overall_precision', 0):.4f}\")\n",
    "print(f\"Recall: {results.get('overall_recall', 0):.4f}\")\n",
    "print(f\"F1 Score: {results.get('overall_f1', 0):.4f}\")\n",
    "print(f\"Accuracy: {results.get('overall_accuracy', 0):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note:* For more detailed metrics, refer to the `seqeval` documentation.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Variants and Extensions of BERT\n",
    "\n",
    "BERT's architecture has inspired numerous variants aimed at improving efficiency, scalability, and performance. We'll explore some of the most notable ones: RoBERTa, DistilBERT, ALBERT, and Domain-Specific BERT models.\n",
    "\n",
    "### 2.1 RoBERTa (Robustly Optimized BERT Pretraining Approach)\n",
    "\n",
    "**Key Enhancements:**\n",
    "\n",
    "- **More Training Data:** Trains on a larger corpus compared to BERT.\n",
    "- **Dynamic Masking:** Applies masking dynamically during training rather than using a fixed masking pattern.\n",
    "- **No Next Sentence Prediction (NSP):** Removes the NSP task, focusing solely on Masked Language Modeling (MLM).\n",
    "- **Larger Batch Sizes and Learning Rates:** Utilizes larger mini-batches and higher learning rates for more efficient training.\n",
    "\n",
    "**Benefits:**\n",
    "\n",
    "- Achieves better performance on various NLP benchmarks.\n",
    "- More robust representations due to optimized training strategies.\n",
    "\n",
    "**Implementation Example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T10:54:14.154886Z",
     "iopub.status.busy": "2024-12-11T10:54:14.154501Z",
     "iopub.status.idle": "2024-12-11T10:54:15.106348Z",
     "shell.execute_reply": "2024-12-11T10:54:15.105372Z",
     "shell.execute_reply.started": "2024-12-11T10:54:14.154852Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: I absolutely loved this movie!\n",
      "Sentiment: {'label': 'LABEL_1', 'score': 0.522160530090332}\n",
      "\n",
      "Sentence: This was the worst film I have ever seen.\n",
      "Sentiment: {'label': 'LABEL_1', 'score': 0.5255693197250366}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load RoBERTa tokenizer and model\n",
    "roberta_tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "roberta_model = RobertaForSequenceClassification.from_pretrained('roberta-base')\n",
    "roberta_model.to(device)\n",
    "\n",
    "# Example usage with a classification pipeline\n",
    "roberta_classifier = pipeline('sentiment-analysis', model=roberta_model, tokenizer=roberta_tokenizer, device=0 if torch.cuda.is_available() else -1)\n",
    "\n",
    "sentences = [\n",
    "    \"I absolutely loved this movie!\",\n",
    "    \"This was the worst film I have ever seen.\"\n",
    "]\n",
    "\n",
    "results = roberta_classifier(sentences)\n",
    "for sentence, sentiment in zip(sentences, results):\n",
    "    print(f\"Sentence: {sentence}\")\n",
    "    print(f\"Sentiment: {sentiment}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 DistilBERT\n",
    "\n",
    "**Key Enhancements:**\n",
    "\n",
    "- **Model Compression:** Reduces the size of BERT by 40% while retaining 97% of its language understanding capabilities.\n",
    "- **Knowledge Distillation:** Trains a smaller model (student) to replicate the behavior of a larger model (teacher).\n",
    "\n",
    "**Benefits:**\n",
    "\n",
    "- Faster inference times.\n",
    "- Reduced computational and memory requirements.\n",
    "- Suitable for deployment in resource-constrained environments.\n",
    "\n",
    "**Implementation Example:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T10:54:20.820282Z",
     "iopub.status.busy": "2024-12-11T10:54:20.819629Z",
     "iopub.status.idle": "2024-12-11T10:54:22.862317Z",
     "shell.execute_reply": "2024-12-11T10:54:22.861316Z",
     "shell.execute_reply.started": "2024-12-11T10:54:20.820252Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c754f836e54499c992c15faea662db1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54635ce76d744d59b6045766f4da15ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a777ba34e1b141a4a02fa6612cd40e53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5df4c1ab2d2d467caf8ca84d970cbbb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25e17e188f344d489d85398be2779cba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: I absolutely loved this movie!\n",
      "Sentiment: {'label': 'LABEL_0', 'score': 0.5197321176528931}\n",
      "\n",
      "Sentence: This was the worst film I have ever seen.\n",
      "Sentiment: {'label': 'LABEL_0', 'score': 0.5332385301589966}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "\n",
    "# Load DistilBERT tokenizer and model\n",
    "distilbert_tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "distilbert_model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\n",
    "distilbert_model.to(device)\n",
    "\n",
    "# Example usage with a classification pipeline\n",
    "distilbert_classifier = pipeline('sentiment-analysis', model=distilbert_model, tokenizer=distilbert_tokenizer, device=0 if torch.cuda.is_available() else -1)\n",
    "\n",
    "sentences = [\n",
    "    \"I absolutely loved this movie!\",\n",
    "    \"This was the worst film I have ever seen.\"\n",
    "]\n",
    "\n",
    "results = distilbert_classifier(sentences)\n",
    "for sentence, sentiment in zip(sentences, results):\n",
    "    print(f\"Sentence: {sentence}\")\n",
    "    print(f\"Sentiment: {sentiment}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 ALBERT (A Lite BERT)\n",
    "\n",
    "**Key Enhancements:**\n",
    "\n",
    "- **Parameter Sharing:** Shares parameters across layers to significantly reduce the total number of parameters.\n",
    "- **Factorized Embedding Parameterization:** Separates the size of hidden layers from the size of embeddings, allowing for smaller embedding sizes without compromising model capacity.\n",
    "\n",
    "**Benefits:**\n",
    "\n",
    "- Significantly fewer parameters compared to BERT.\n",
    "- Comparable or better performance with a reduced memory footprint.\n",
    "- Faster training and inference.\n",
    "\n",
    "**Implementation Example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T10:54:42.418172Z",
     "iopub.status.busy": "2024-12-11T10:54:42.417778Z",
     "iopub.status.idle": "2024-12-11T10:54:43.801881Z",
     "shell.execute_reply": "2024-12-11T10:54:43.801014Z",
     "shell.execute_reply.started": "2024-12-11T10:54:42.418139Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bd17aa41e3e4c69933a0300f5427066",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55ce0a5f2c154c8eab4a3205a3df27b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/760k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cb31dab5de049e09265498fa08d90b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df2702b2d1664ba190cb83916650b727",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/684 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b071ec619254f5f90e6e7cd2688d846",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/47.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: I absolutely loved this movie!\n",
      "Sentiment: {'label': 'LABEL_1', 'score': 0.6166632175445557}\n",
      "\n",
      "Sentence: This was the worst film I have ever seen.\n",
      "Sentiment: {'label': 'LABEL_1', 'score': 0.6308166980743408}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AlbertTokenizer, AlbertForSequenceClassification\n",
    "\n",
    "# Load ALBERT tokenizer and model\n",
    "albert_tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2')\n",
    "albert_model = AlbertForSequenceClassification.from_pretrained('albert-base-v2')\n",
    "albert_model.to(device)\n",
    "\n",
    "# Example usage with a classification pipeline\n",
    "albert_classifier = pipeline('sentiment-analysis', model=albert_model, tokenizer=albert_tokenizer, device=0 if torch.cuda.is_available() else -1)\n",
    "\n",
    "sentences = [\n",
    "    \"I absolutely loved this movie!\",\n",
    "    \"This was the worst film I have ever seen.\"\n",
    "]\n",
    "\n",
    "results = albert_classifier(sentences)\n",
    "for sentence, sentiment in zip(sentences, results):\n",
    "    print(f\"Sentence: {sentence}\")\n",
    "    print(f\"Sentiment: {sentiment}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Domain-Specific BERT Models\n",
    "\n",
    "Pre-trained BERT models tailored to specific domains can outperform general-purpose BERT models on tasks within those domains.\n",
    "\n",
    "**Examples:**\n",
    "\n",
    "- **BioBERT:** Specialized for biomedical text mining tasks.\n",
    "- **SciBERT:** Designed for scientific publications.\n",
    "- **FinBERT:** Tailored for financial text analysis.\n",
    "\n",
    "**Implementation Example with BioBERT:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T10:55:11.316910Z",
     "iopub.status.busy": "2024-12-11T10:55:11.316534Z",
     "iopub.status.idle": "2024-12-11T10:55:14.660098Z",
     "shell.execute_reply": "2024-12-11T10:55:14.659002Z",
     "shell.execute_reply.started": "2024-12-11T10:55:11.316877Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6e11a1f4d9f4ad08a796e7ee2760529",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/313 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1a67589878f4a80a60433ef868d5cc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17242f252a4f463389b0446fabc00201",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: The patient was diagnosed with hypertension.\n",
      "Sentiment: {'label': 'LABEL_1', 'score': 0.505736768245697}\n",
      "\n",
      "Sentence: CRISPR-Cas9 is a revolutionary gene-editing tool.\n",
      "Sentiment: {'label': 'LABEL_1', 'score': 0.5348502397537231}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Load BioBERT tokenizer and model\n",
    "biobert_tokenizer = AutoTokenizer.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\")\n",
    "biobert_model = AutoModelForSequenceClassification.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\")\n",
    "biobert_model.to(device)\n",
    "\n",
    "# Example usage with a classification pipeline (assuming a relevant task)\n",
    "biobert_classifier = pipeline('sentiment-analysis', model=biobert_model, tokenizer=biobert_tokenizer, device=0 if torch.cuda.is_available() else -1)\n",
    "\n",
    "# Example biomedical sentences\n",
    "sentences = [\n",
    "    \"The patient was diagnosed with hypertension.\",\n",
    "    \"CRISPR-Cas9 is a revolutionary gene-editing tool.\"\n",
    "]\n",
    "\n",
    "results = biobert_classifier(sentences)\n",
    "for sentence, sentiment in zip(sentences, results):\n",
    "    print(f\"Sentence: {sentence}\")\n",
    "    print(f\"Sentiment: {sentiment}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploring BERT Variants and Extensions\n",
    "\n",
    "BERT's architecture has inspired numerous variants aimed at improving efficiency, scalability, and performance. We'll delve into some prominent variants: RoBERTa, DistilBERT, ALBERT, and Domain-Specific BERT models.\n",
    "\n",
    "### 3.1 RoBERTa (Robustly Optimized BERT Pretraining Approach)\n",
    "\n",
    "**Key Enhancements:**\n",
    "\n",
    "- **More Training Data:** Trains on a significantly larger corpus compared to BERT.\n",
    "- **Dynamic Masking:** Applies masking dynamically during training rather than using a fixed masking pattern.\n",
    "- **No Next Sentence Prediction (NSP):** Removes the NSP task, focusing solely on Masked Language Modeling (MLM).\n",
    "- **Larger Batch Sizes and Learning Rates:** Utilizes larger mini-batches and higher learning rates for more efficient training.\n",
    "\n",
    "**Benefits:**\n",
    "\n",
    "- Achieves better performance on various NLP benchmarks.\n",
    "- More robust representations due to optimized training strategies.\n",
    "\n",
    "**Implementation Example:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T10:55:21.643918Z",
     "iopub.status.busy": "2024-12-11T10:55:21.643220Z",
     "iopub.status.idle": "2024-12-11T10:55:22.153632Z",
     "shell.execute_reply": "2024-12-11T10:55:22.152696Z",
     "shell.execute_reply.started": "2024-12-11T10:55:21.643883Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: I absolutely loved this movie!\n",
      "Sentiment: {'label': 'LABEL_1', 'score': 0.5146975517272949}\n",
      "\n",
      "Sentence: This was the worst film I have ever seen.\n",
      "Sentiment: {'label': 'LABEL_1', 'score': 0.5187569856643677}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "\n",
    "# Load RoBERTa tokenizer and model\n",
    "roberta_tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "roberta_model = RobertaForSequenceClassification.from_pretrained('roberta-base')\n",
    "roberta_model.to(device)\n",
    "\n",
    "# Example usage with a classification pipeline\n",
    "roberta_classifier = pipeline('sentiment-analysis', model=roberta_model, tokenizer=roberta_tokenizer, device=0 if torch.cuda.is_available() else -1)\n",
    "\n",
    "sentences = [\n",
    "    \"I absolutely loved this movie!\",\n",
    "    \"This was the worst film I have ever seen.\"\n",
    "]\n",
    "\n",
    "results = roberta_classifier(sentences)\n",
    "for sentence, sentiment in zip(sentences, results):\n",
    "    print(f\"Sentence: {sentence}\")\n",
    "    print(f\"Sentiment: {sentiment}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 DistilBERT\n",
    "\n",
    "**Key Enhancements:**\n",
    "\n",
    "- **Model Compression:** Reduces the size of BERT by 40% while retaining 97% of its language understanding capabilities.\n",
    "- **Knowledge Distillation:** Trains a smaller model (student) to replicate the behavior of a larger model (teacher).\n",
    "\n",
    "**Benefits:**\n",
    "\n",
    "- Faster inference times.\n",
    "- Reduced computational and memory requirements.\n",
    "- Suitable for deployment in resource-constrained environments.\n",
    "\n",
    "**Implementation Example:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T10:55:33.813605Z",
     "iopub.status.busy": "2024-12-11T10:55:33.813234Z",
     "iopub.status.idle": "2024-12-11T10:55:34.160206Z",
     "shell.execute_reply": "2024-12-11T10:55:34.159387Z",
     "shell.execute_reply.started": "2024-12-11T10:55:33.813567Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: I absolutely loved this movie!\n",
      "Sentiment: {'label': 'LABEL_1', 'score': 0.5239751935005188}\n",
      "\n",
      "Sentence: This was the worst film I have ever seen.\n",
      "Sentiment: {'label': 'LABEL_1', 'score': 0.5243285298347473}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "\n",
    "# Load DistilBERT tokenizer and model\n",
    "distilbert_tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "distilbert_model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\n",
    "distilbert_model.to(device)\n",
    "\n",
    "# Example usage with a classification pipeline\n",
    "distilbert_classifier = pipeline('sentiment-analysis', model=distilbert_model, tokenizer=distilbert_tokenizer, device=0 if torch.cuda.is_available() else -1)\n",
    "\n",
    "sentences = [\n",
    "    \"I absolutely loved this movie!\",\n",
    "    \"This was the worst film I have ever seen.\"\n",
    "]\n",
    "\n",
    "results = distilbert_classifier(sentences)\n",
    "for sentence, sentiment in zip(sentences, results):\n",
    "    print(f\"Sentence: {sentence}\")\n",
    "    print(f\"Sentiment: {sentiment}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 ALBERT (A Lite BERT)\n",
    "\n",
    "**Key Enhancements:**\n",
    "\n",
    "- **Parameter Sharing:** Shares parameters across layers to significantly reduce the total number of parameters.\n",
    "- **Factorized Embedding Parameterization:** Separates the size of hidden layers from the size of embeddings, allowing for smaller embedding sizes without compromising model capacity.\n",
    "\n",
    "**Benefits:**\n",
    "\n",
    "- Significantly fewer parameters compared to BERT.\n",
    "- Comparable or better performance with a reduced memory footprint.\n",
    "- Faster training and inference.\n",
    "\n",
    "**Implementation Example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T10:55:40.754137Z",
     "iopub.status.busy": "2024-12-11T10:55:40.753740Z",
     "iopub.status.idle": "2024-12-11T10:55:41.154229Z",
     "shell.execute_reply": "2024-12-11T10:55:41.153077Z",
     "shell.execute_reply.started": "2024-12-11T10:55:40.754103Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: I absolutely loved this movie!\n",
      "Sentiment: {'label': 'LABEL_0', 'score': 0.5040313005447388}\n",
      "\n",
      "Sentence: This was the worst film I have ever seen.\n",
      "Sentiment: {'label': 'LABEL_1', 'score': 0.5025427341461182}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AlbertTokenizer, AlbertForSequenceClassification\n",
    "\n",
    "# Load ALBERT tokenizer and model\n",
    "albert_tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2')\n",
    "albert_model = AlbertForSequenceClassification.from_pretrained('albert-base-v2')\n",
    "albert_model.to(device)\n",
    "\n",
    "# Example usage with a classification pipeline\n",
    "albert_classifier = pipeline('sentiment-analysis', model=albert_model, tokenizer=albert_tokenizer, device=0 if torch.cuda.is_available() else -1)\n",
    "\n",
    "sentences = [\n",
    "    \"I absolutely loved this movie!\",\n",
    "    \"This was the worst film I have ever seen.\"\n",
    "]\n",
    "\n",
    "results = albert_classifier(sentences)\n",
    "for sentence, sentiment in zip(sentences, results):\n",
    "    print(f\"Sentence: {sentence}\")\n",
    "    print(f\"Sentiment: {sentiment}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Domain-Specific BERT Models\n",
    "\n",
    "Pre-trained BERT models tailored to specific domains can outperform general-purpose BERT models on tasks within those domains.\n",
    "\n",
    "**Examples:**\n",
    "\n",
    "- **BioBERT:** Specialized for biomedical text mining tasks.\n",
    "- **SciBERT:** Designed for scientific publications.\n",
    "- **FinBERT:** Tailored for financial text analysis.\n",
    "\n",
    "**Implementation Example with BioBERT:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T10:55:59.381410Z",
     "iopub.status.busy": "2024-12-11T10:55:59.380707Z",
     "iopub.status.idle": "2024-12-11T10:56:00.178712Z",
     "shell.execute_reply": "2024-12-11T10:56:00.177826Z",
     "shell.execute_reply.started": "2024-12-11T10:55:59.381374Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: The patient was diagnosed with hypertension.\n",
      "Sentiment: {'label': 'LABEL_1', 'score': 0.6780614852905273}\n",
      "\n",
      "Sentence: CRISPR-Cas9 is a revolutionary gene-editing tool.\n",
      "Sentiment: {'label': 'LABEL_1', 'score': 0.6932359337806702}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Load BioBERT tokenizer and model\n",
    "biobert_tokenizer = AutoTokenizer.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\")\n",
    "biobert_model = AutoModelForSequenceClassification.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\")\n",
    "biobert_model.to(device)\n",
    "\n",
    "# Example usage with a classification pipeline (assuming a relevant task)\n",
    "biobert_classifier = pipeline('sentiment-analysis', model=biobert_model, tokenizer=biobert_tokenizer, device=0 if torch.cuda.is_available() else -1)\n",
    "\n",
    "# Example biomedical sentences\n",
    "sentences = [\n",
    "    \"The patient was diagnosed with hypertension.\",\n",
    "    \"CRISPR-Cas9 is a revolutionary gene-editing tool.\"\n",
    "]\n",
    "\n",
    "results = biobert_classifier(sentences)\n",
    "for sentence, sentiment in zip(sentences, results):\n",
    "    print(f\"Sentence: {sentence}\")\n",
    "    print(f\"Sentiment: {sentiment}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "#### *Note:* Domain-specific models may require task-specific fine-tuning to achieve optimal performance.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Analysis and Insights\n",
    "\n",
    "### 4.1 Advantages of BERT Over Traditional RNNs\n",
    "\n",
    "- **Bidirectional Contextualization:** BERT considers both left and right context simultaneously, enabling a deeper understanding of language nuances.\n",
    "- **Pre-training with MLM and NSP:** BERT's pre-training tasks allow it to learn rich language representations that can be fine-tuned for various downstream tasks.\n",
    "- **Transfer Learning:** Fine-tuning pre-trained BERT models on specific tasks often leads to state-of-the-art performance with relatively small task-specific datasets.\n",
    "- **Handling Long-Range Dependencies:** The self-attention mechanism in BERT effectively captures dependencies between distant tokens in a sequence.\n",
    "\n",
    "### 4.2 Challenges and Considerations\n",
    "\n",
    "- **Computational Resources:** BERT models are large and require significant memory and computational power, especially during training.\n",
    "- **Fine-Tuning Sensitivity:** BERT can be sensitive to hyperparameters during fine-tuning, necessitating careful tuning for optimal performance.\n",
    "- **Interpretability:** While attention mechanisms provide some interpretability, understanding the full decision-making process of BERT remains complex.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Further Steps and Resources\n",
    "\n",
    "### 5.1 Experiment with Different Tasks\n",
    "\n",
    "- **Named Entity Recognition (NER)**\n",
    "- **Question Answering (QA)**\n",
    "- **Text Summarization**\n",
    "\n",
    "### 5.2 Explore BERT Variants\n",
    "\n",
    "- **RoBERTa:** Explore its improved training methodology.\n",
    "- **DistilBERT:** Implement a distilled version for efficiency.\n",
    "- **ALBERT:** Experiment with parameter-efficient BERT variants.\n",
    "\n",
    "### 5.3 Dive Deeper into Transformers\n",
    "\n",
    "- **Transformer-XL:** Understand its approach to handling longer sequences.\n",
    "- **GPT Series:** Explore generative capabilities using decoder-only models.\n",
    "\n",
    "### 5.4 Utilize Hugging Face Resources\n",
    "\n",
    "- **Hugging Face Models:** Explore a wide range of pre-trained models.\n",
    "- **Hugging Face Tutorials:** Engage with comprehensive tutorials for various NLP tasks.\n",
    "\n",
    "**Remember:** Mastering BERT and its variants is pivotal for advancing in modern NLP. Leveraging pre-trained models and understanding their architecture enables you to tackle complex language understanding tasks with efficiency and effectiveness.\n",
    "\n",
    "---\n",
    "\n",
    "## References\n",
    "\n",
    "- [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805) by Devlin et al.\n",
    "- [The Illustrated BERT, ELMo, and co. (How NLP Cracked Transfer Learning)](http://jalammar.github.io/illustrated-bert/)\n",
    "- [Hugging Face Transformers Documentation](https://huggingface.co/transformers/)\n",
    "- [The Illustrated Transformer](http://jalammar.github.io/illustrated-transformer/)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30804,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
